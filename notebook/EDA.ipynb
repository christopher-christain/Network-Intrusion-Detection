{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c90c66c9",
   "metadata": {},
   "source": [
    "### IMPORTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9297a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data-set\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\User\\Desktop\\Network-Intrusion-Detection\\data\\raw-data\\Train_data.csv\")\n",
    "data2 = pd.read_csv(r\"C:\\Users\\User\\Desktop\\Network-Intrusion-Detection\\data\\raw-data\\Test_data.csv\")\n",
    "\n",
    "data.head(20)\n",
    "data2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e4579",
   "metadata": {},
   "source": [
    "### Data preprocessing part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1767ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The row and columns of the dataset\", data.shape)\n",
    "print(\"the row and columns of the dataset2\", data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283cfd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a58544",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25840f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing value\n",
    "\n",
    "for col in data.columns:\n",
    "    missing_value = data[col].isnull().sum()\n",
    "    if missing_value > 0:\n",
    "        print(f\"{col}: {missing_value} missing values\")\n",
    "    else:\n",
    "        print(\"There are no missing value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964027af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((data.isnull().sum()[lambda x: x > 0] / len(data) * 100)\n",
    "      .round(3)\n",
    "      .astype(str) + ' %')\n",
    "\n",
    "missing_info = data.isnull().sum()\n",
    "missing_info = missing_info[missing_info > 0].to_frame('Missing Count')\n",
    "missing_info['Missing %'] = (missing_info['Missing Count'] / len(data) * 100).round(3)\n",
    "print(missing_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a34826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "\n",
    "print(f\"number of duplicated rows: {data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers\n",
    "\n",
    "# Filter numeric columns except 'class'\n",
    "numeric_cols = [col for col in data.columns if col != 'class' and is_numeric_dtype(data[col])]\n",
    "\n",
    "# Grid setup\n",
    "n_cols = 2  # Boxplot + Scatterplot side by side for each feature\n",
    "n_rows = len(numeric_cols)\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 4 * n_rows))\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    # Boxplot\n",
    "    sns.boxplot(x=data[col], ax=axes[i, 0])\n",
    "    axes[i, 0].set_title(f\"Boxplot of {col}\")\n",
    "    \n",
    "    # Scatterplot vs class\n",
    "    sns.scatterplot(data=data, x=data[col], y=data['class'], ax=axes[i, 1])\n",
    "    axes[i, 1].set_title(f\"Scatterplot of {col} vs class\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b53d3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out only numeric columns for correlation calculation\n",
    "numeric_train = data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Generate the heatmap\n",
    "plt.figure(figsize=(40,30))\n",
    "sns.heatmap(numeric_train.corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168667a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this two columns are redundant\n",
    "\n",
    "print(data[\"is_host_login\"].value_counts())\n",
    "print(data[\"num_outbound_cmds\"].value_counts())\n",
    "\n",
    "print(data2[\"is_host_login\"].value_counts())\n",
    "print(data2[\"num_outbound_cmds\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ca655",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"num_outbound_cmds\"], axis=1, inplace=True)\n",
    "data2.drop([\"num_outbound_cmds\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd173ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"is_host_login\"], axis=1, inplace=True)\n",
    "data2.drop([\"is_host_login\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25996d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking attack class distributiion\n",
    "print(\"value count for class\",data[\"class\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include=[\"float64\", \"int64\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa6be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include=[\"object\"]).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9069be0e",
   "metadata": {},
   "source": [
    "### Scaling Numerical Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d93dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# extract numerical attributes\n",
    "cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Fit only on train\n",
    "sc_data  = scaler.fit_transform(data[cols])\n",
    "\n",
    "# Use the same scaler to transform test\n",
    "sc_test = scaler.transform(data2[cols])\n",
    "\n",
    "# turn the result back to dataframes\n",
    "sc_traindf = pd.DataFrame(sc_data, columns=cols, index=data.index)\n",
    "sc_testdf = pd.DataFrame(sc_test, columns=cols, index=data2.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a15bd9",
   "metadata": {},
   "source": [
    "### Encoding Categorical attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f31b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_categoricals(data, data2, target_col):\n",
    "    encoders = {}\n",
    "    \n",
    "    # Copy data\n",
    "    cat_data = data.select_dtypes(include=['object']).copy()\n",
    "    cat_data2 = data2.select_dtypes(include=['object']).copy()\n",
    "\n",
    "    for col in cat_data.columns:\n",
    "        le = LabelEncoder()\n",
    "        data_vals = cat_data[col].astype(str)\n",
    "\n",
    "        # Fit only on train data\n",
    "        cat_data[col] = le.fit_transform(data_vals)\n",
    "\n",
    "        # Transform test, handle unseen labels â†’ -1\n",
    "        data2_vals = cat_data2[col].astype(str)\n",
    "        data2_encoded = []\n",
    "        for val in data2_vals:\n",
    "            if val in le.classes_:\n",
    "                data2_encoded.append(le.transform([val])[0])\n",
    "            else:\n",
    "                data2_encoded.append(-1)  # unseen label placeholder\n",
    "        cat_data2[col] = data2_encoded\n",
    "\n",
    "        encoders[col] = le\n",
    "\n",
    "    # Separate features and target\n",
    "    X_train = cat_data.drop(columns=[target_col])\n",
    "    y_train = cat_data[target_col]\n",
    "\n",
    "    X_test = cat_data2.drop(columns=[target_col])\n",
    "    y_test = cat_data2[target_col]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, encoders\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00139409",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, y_train, X_test, y_test, encoders = encode_categoricals(data, data2, target_col=\"class\")\n",
    "print(\"Encoding features shape:\", X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f321f506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (25192, 39) (25192,) (22544, 39)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_categoricals(train, test, target_col):\n",
    "    encoders = {}\n",
    "\n",
    "    # 1. Separate target column (only from train)\n",
    "    y_train = train[target_col].copy()\n",
    "    X_train = train.drop(columns=[target_col]).copy()\n",
    "    X_test = test.copy()\n",
    "\n",
    "    # 2. Encode only categorical (object) columns\n",
    "    cat_cols = X_train.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
    "\n",
    "        # Handle unseen categories in test â†’ -1\n",
    "        mapping = {cls: i for i, cls in enumerate(le.classes_)}\n",
    "        X_test[col] = X_test[col].astype(str).map(mapping).fillna(-1).astype(int)\n",
    "\n",
    "        encoders[col] = le\n",
    "\n",
    "    # Since test has no target_col\n",
    "    y_test = None  \n",
    "\n",
    "    return X_train, y_train, X_test, y_test, encoders\n",
    "X_train, y_train, X_test, y_test, encoders = encode_categoricals(data, data2, target_col=\"class\")\n",
    "print(\"Shapes:\", X_train.shape, y_train.shape, X_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "54630d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 39)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b75973d",
   "metadata": {},
   "source": [
    "### Using RandomForestClassifier for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccf1256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearm.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
